{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import nltk\n",
    "import pathlib\n",
    "import io\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load full list of 121 words/phrases from CDC guidelines\n",
    "with open('./CDC_difficult_all.txt','r') as f:\n",
    "    difficult_all = f.readlines()\n",
    "    difficult_all = [x.strip() for x in difficult_all]\n",
    "# total number of words\n",
    "len(difficult_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many words in list appear at least once in text\n",
    "def howManyWords (words, text):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        if word.lower() in tokens:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count aggregate instances of list of words/phrases in a text\n",
    "def cumulativeCount(words, text):\n",
    "    counts = []\n",
    "    for word in words:\n",
    "        count = sum(1 for _ in re.finditer(r'\\b%s\\b' % re.escape(word), text.lower()))\n",
    "        counts.append(count)\n",
    "    return sum(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory of txt files to be analyzed\n",
    "path = pathlib.Path(\"./CDC_txt_all\")\n",
    "\n",
    "filename = []\n",
    "token_count = []\n",
    "\n",
    "count = []\n",
    "frac = []\n",
    "total = []\n",
    "freq =[]\n",
    "\n",
    "# loop through each file\n",
    "for entry in path.iterdir():\n",
    "    if entry.is_file(): \n",
    "        with io.open(entry, 'r', encoding='windows-1252') as f:\n",
    "        #with open(entry,'r') as f:\n",
    "            \n",
    "            raw = f.read()\n",
    "            tokens = nltk.word_tokenize(raw)\n",
    "            \n",
    "            # count of difficult words and phrases that appear at least once \n",
    "            difficult_count = howManyWords(difficult_all, raw)\n",
    "            # fraction of difficult words and phrases appearing\n",
    "            difficult_frac = difficult_count / len(difficult_all)\n",
    "            \n",
    "            # total instances of difficult words and phrases\n",
    "            difficult_total = cumulativeCount(difficult_all, raw)\n",
    "            # per-token frequency of difficult words and phrases\n",
    "            difficult_freq = difficult_total / len(tokens)\n",
    "            \n",
    "            filename.append(entry)\n",
    "            token_count.append(len(tokens))\n",
    "            \n",
    "            count.append(difficult_count)\n",
    "            frac.append(difficult_frac)\n",
    "            total.append(difficult_total)\n",
    "            freq.append(difficult_freq) \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 11, 18, 12, 13, 9, 5, 31, 8, 10, 0, 27, 4, 4, 13, 3, 7, 22, 16, 0, 23, 26, 12, 8, 10, 7, 28, 48, 6, 3, 8, 5, 6, 11, 3, 20, 10, 4, 9, 11, 7, 3, 15, 6, 4, 5, 15, 5, 12, 23, 15, 5, 11, 19, 11, 10, 7, 22, 11, 24, 11, 13, 13, 4, 8, 20, 11, 6, 3]\n",
      "[0.1322314049586777, 0.09090909090909091, 0.1487603305785124, 0.09917355371900827, 0.10743801652892562, 0.0743801652892562, 0.04132231404958678, 0.256198347107438, 0.06611570247933884, 0.08264462809917356, 0.0, 0.2231404958677686, 0.03305785123966942, 0.03305785123966942, 0.10743801652892562, 0.024793388429752067, 0.05785123966942149, 0.18181818181818182, 0.1322314049586777, 0.0, 0.19008264462809918, 0.21487603305785125, 0.09917355371900827, 0.06611570247933884, 0.08264462809917356, 0.05785123966942149, 0.23140495867768596, 0.39669421487603307, 0.049586776859504134, 0.024793388429752067, 0.06611570247933884, 0.04132231404958678, 0.049586776859504134, 0.09090909090909091, 0.024793388429752067, 0.1652892561983471, 0.08264462809917356, 0.03305785123966942, 0.0743801652892562, 0.09090909090909091, 0.05785123966942149, 0.024793388429752067, 0.12396694214876033, 0.049586776859504134, 0.03305785123966942, 0.04132231404958678, 0.12396694214876033, 0.04132231404958678, 0.09917355371900827, 0.19008264462809918, 0.12396694214876033, 0.04132231404958678, 0.09090909090909091, 0.15702479338842976, 0.09090909090909091, 0.08264462809917356, 0.05785123966942149, 0.18181818181818182, 0.09090909090909091, 0.19834710743801653, 0.09090909090909091, 0.10743801652892562, 0.10743801652892562, 0.03305785123966942, 0.06611570247933884, 0.1652892561983471, 0.09090909090909091, 0.049586776859504134, 0.024793388429752067]\n",
      "[37, 15, 54, 30, 51, 32, 6, 222, 9, 27, 0, 159, 13, 6, 32, 4, 14, 62, 41, 0, 60, 240, 30, 12, 15, 12, 111, 574, 12, 7, 12, 10, 6, 31, 8, 87, 16, 8, 16, 30, 9, 5, 28, 9, 5, 15, 37, 8, 32, 156, 27, 8, 30, 49, 33, 19, 11, 60, 17, 88, 29, 39, 22, 11, 10, 92, 20, 10, 3]\n",
      "[0.039403620873269436, 0.01687289088863892, 0.05432595573440644, 0.031545741324921134, 0.02954808806488992, 0.03733955659276546, 0.01634877384196185, 0.03450419645632577, 0.03409090909090909, 0.01946647440519106, 0.0, 0.03251533742331288, 0.08125, 0.023622047244094488, 0.0365296803652968, 0.030303030303030304, 0.03357314148681055, 0.02454473475851148, 0.021878335112059766, 0.0, 0.019218449711723255, 0.025504782146652496, 0.0199468085106383, 0.009531374106433678, 0.033860045146726865, 0.013824884792626729, 0.02626597255087553, 0.049602488765986864, 0.039735099337748346, 0.009873060648801129, 0.03550295857988166, 0.0390625, 0.03225806451612903, 0.03153611393692777, 0.08695652173913043, 0.03800786369593709, 0.025559105431309903, 0.008247422680412371, 0.031067961165048542, 0.03759398496240601, 0.032490974729241874, 0.010416666666666666, 0.051001821493624776, 0.025936599423631124, 0.06756756756756757, 0.04437869822485207, 0.025050778605280974, 0.03669724770642202, 0.03636363636363636, 0.03394994559303591, 0.022076860179885527, 0.014787430683918669, 0.031982942430703626, 0.026967528893780957, 0.04576976421636616, 0.027818448023426062, 0.06875, 0.027210884353741496, 0.025487256371814093, 0.0352, 0.03567035670356704, 0.05277401894451962, 0.026378896882494004, 0.03859649122807018, 0.027855153203342618, 0.033973412112259974, 0.03875968992248062, 0.0234192037470726, 0.04411764705882353]\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "print(count)\n",
    "print(frac)\n",
    "print(total)\n",
    "print(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export results to csv\n",
    "df_filename = pd.DataFrame({'file': filename})\n",
    "df_token_count = pd.DataFrame({'tokens': token_count})\n",
    "df_count = pd.DataFrame({'raw count all': count})\n",
    "df_frac = pd.DataFrame({'fraction all': frac})\n",
    "df_total = pd.DataFrame({'raw total count all': total})\n",
    "df_freq = pd.DataFrame({'frequency all': freq})\n",
    "\n",
    "df_combined = pd.concat([df_filename, df_token_count, df_count, df_frac, df_total, df_freq], axis=1)\n",
    "df_combined_final = df_combined.round(3).sort_values(by='file')\n",
    "df_combined_final.to_csv('./CDC_difficult_words_analysis.csv', sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
